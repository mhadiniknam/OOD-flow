{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/dihjiang/OOD-flow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:54:22.186792Z","iopub.execute_input":"2025-05-24T16:54:22.187081Z","iopub.status.idle":"2025-05-24T16:54:22.580974Z","shell.execute_reply.started":"2025-05-24T16:54:22.187060Z","shell.execute_reply":"2025-05-24T16:54:22.579979Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'OOD-flow'...\nremote: Enumerating objects: 89, done.\u001b[K\nremote: Counting objects: 100% (89/89), done.\u001b[K\nremote: Compressing objects: 100% (67/67), done.\u001b[K\nremote: Total 89 (delta 31), reused 47 (delta 14), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (89/89), 48.82 KiB | 3.75 MiB/s, done.\nResolving deltas: 100% (31/31), done.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"cd OOD-flow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:54:24.696061Z","iopub.execute_input":"2025-05-24T16:54:24.696327Z","iopub.status.idle":"2025-05-24T16:54:24.701856Z","shell.execute_reply.started":"2025-05-24T16:54:24.696305Z","shell.execute_reply":"2025-05-24T16:54:24.701116Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/OOD-flow/OOD-flow\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:54:24.849862Z","iopub.execute_input":"2025-05-24T16:54:24.850528Z","iopub.status.idle":"2025-05-24T16:54:24.997910Z","shell.execute_reply.started":"2025-05-24T16:54:24.850502Z","shell.execute_reply":"2025-05-24T16:54:24.996917Z"}},"outputs":[{"name":"stdout","text":"datasets  generateImgs.py  main.py  models  README.md  result_helpers  utils.py\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install -e .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:54:26.436481Z","iopub.execute_input":"2025-05-24T16:54:26.437204Z","iopub.status.idle":"2025-05-24T16:54:27.868991Z","shell.execute_reply.started":"2025-05-24T16:54:26.437171Z","shell.execute_reply":"2025-05-24T16:54:27.868110Z"}},"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/OOD-flow/OOD-flow\n\u001b[31mERROR: file:///kaggle/working/OOD-flow/OOD-flow does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import sys\nsys.path.append('./')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:54:27.870750Z","iopub.execute_input":"2025-05-24T16:54:27.871016Z","iopub.status.idle":"2025-05-24T16:54:27.875122Z","shell.execute_reply.started":"2025-05-24T16:54:27.870993Z","shell.execute_reply":"2025-05-24T16:54:27.874214Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import argparse\n\ndef parse_arguments():\n    \"\"\"\n    Argument parser.\n\n    :return: the command line arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description='OOD detection with flow models',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    # use autoencoder (or not)\n    parser.add_argument('--autoencoder', default=None, type=str,\n                        help='The Autoencoder framework. Choose among `LSA`', metavar='')\n\n    # density estimator / flow model\n    parser.add_argument('--estimator', default='REALNVP', type=str,\n                        help='The name of density estimator / flow model. Choose among `REALNVP`', metavar='')\n\n    # Dataset\n    parser.add_argument('--dataset', default='mnist', type=str,\n                        help='The name of the dataset', metavar='')\n\n    # specify the In-Distribution (dataset name or class name)\n    parser.add_argument('--ind', type=str, default='1',\n                        help='In-distribution dataset (or class) name')\n\n    # Setting model mode (Train or Test)\n    parser.add_argument('--Train', dest='trainflag', action='store_true', default=True,\n                        help='Train Mode')\n    parser.add_argument('--Test', dest='testflag', action='store_true', default=False,\n                        help='Test Mode')\n\n    parser.add_argument('--batch_size', type=int, default=256,\n                        help='input batch size for training (default: 256)')\n    parser.add_argument('--epochs', type=int, default=200,\n                        help='number of epochs to train (default: 200)')\n    parser.add_argument('--lr', type=float, default=0.00001,\n                        help='learning rate (default: 0.00001)')\n\n    # model specifications\n    parser.add_argument('--num_blocks', type=int, default=1,\n                        help='number of invertible blocks (default: 1)')\n    parser.add_argument('--code_length', type=int, default=64,\n                        help='length of latent code of autoencoder (default: 64)')\n    parser.add_argument('--hidden_size', type=int, default=2048,\n                        help='length of hidden vector (default: 2048)')\n    parser.add_argument('--K', type=int, default=3,\n                        help='number of flow steps in Glow (original default: 32)')\n    parser.add_argument('--n_class', type=int, default=10,\n                        help='Number of classes used in experiments')\n\n    # detection rules\n    parser.add_argument('--density_rule', dest='density_rule_flag', action='store_true', default=True,\n                        help='plot histogram and ROC using density as detection score')\n    parser.add_argument('--kst_rule', dest='kst_rule_flag', action='store_true', default=True,\n                        help='plot histogram and ROC using discrepancy rule (ks-test)')\n    parser.add_argument('--klod', dest='klod_flag', action='store_true', default=True,\n                        help='plot histogram and ROC using KLOD')\n    parser.add_argument('--typical', dest='typical_flag', action='store_true', default=False,\n                        help='typicality test')\n\n    # number of projected dimensions\n    parser.add_argument('--num_project', type=int, default=200,\n                        help='number of projected dimensions (default: 200)')\n    # number of epochs for loading models\n    parser.add_argument('--num_epochs', type=int, default=-1,\n                        help='for loading differently trained models')\n    parser.add_argument('--lam', type=float, default=1.0,\n                        help='trade off between reconstruction loss and auto-regression loss')\n    parser.add_argument('--seed', type=int, default=1,\n                        help='random_seed')\n    parser.add_argument('--log_step', type=int, default=100,\n                        help='log_step, save model for every #log_step epochs')\n\n    parser.add_argument('--add_noise', dest='noise_flag', action='store_true', default=False,\n                        help='add noise to input images')\n    parser.add_argument('--sigma', type=float, default=1.0,\n                        help='sigma of noise')\n    parser.add_argument('--seg_len', type=int, default=10,\n                        help='length of segment of EEG/ECG')\n\n    # Use parse_known_args if you run this in Jupyter/Colab to avoid unrecognized argument errors\n    args, unknown = parser.parse_known_args()\n    return args\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:57:48.781801Z","iopub.execute_input":"2025-05-24T16:57:48.782463Z","iopub.status.idle":"2025-05-24T16:57:48.792037Z","shell.execute_reply.started":"2025-05-24T16:57:48.782436Z","shell.execute_reply":"2025-05-24T16:57:48.791349Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import argparse\nfrom argparse import Namespace\nimport os\nimport torch\nimport numpy as np\nimport torch.nn as nn\n\n# datasets\nfrom datasets import *\n# models\n# auto-encoder\nfrom models.LSA_mnist import LSA_MNIST\nfrom models.LSA_cifar10 import LSA_CIFAR10\n# density estimator\nfrom models.transform_realnvp import TinvREALNVP\nfrom models.glow_models import Glow\n# random seed\nfrom utils import set_random_seed\nfrom result_helpers.ood_trainer import OODTrainer\n# path\nfrom utils import create_checkpoints_dir\n\nimport time\n\nsys.argv = ['']\n\ndef setDataset(ds_name, n_class, ind, train_intra, seg_len):\n    if ds_name == 'mnist':\n        dataset = MNIST(path='data/MNIST', n_class=n_class, InD=ind)\n    elif ds_name == 'fmnist':\n        dataset = FMNIST(path='data/FMNIST', n_class=n_class, InD=ind, train_intra=train_intra)\n    elif ds_name == 'kmnist':\n        dataset = KMNIST(path='data/KMNIST', InD=ind)\n    elif ds_name == 'omniglot':\n        dataset = OMNIGLOT(path='data/OMNIGLOT', InD=ind)\n    elif ds_name == 'ecg':\n        dataset = ECG(path='data/PSG', InD=ind, seg_len=seg_len)\n    elif ds_name == 'eeg':\n        dataset = EEG(path='data/PSG', InD=ind, seg_len=seg_len)\n    elif ds_name == 'cifar10':\n        dataset = CIFAR10(path='data/CIFAR10', n_class=n_class, InD=ind, train_intra=train_intra)\n    elif ds_name == 'svhn':\n        dataset = SVHN(path='data/SVHN', n_class=n_class, InD=ind)\n    elif ds_name == 'cifar100':\n        dataset = CIFAR100(path='data/CIFAR100', n_class=n_class, InD=ind)\n    elif ds_name == 'celeba':\n        dataset = CELEBA(path='data/CELEBA', InD=ind)\n    elif ds_name == 'lsun':\n        dataset = LSUN(path='data/LSUN', InD=ind)\n    elif ds_name in ['random', 'const']:\n        dataset = FAKE(ds_name, ind)\n    elif 'gaussian' in ds_name:\n        dataset = GAUSSIAN(ds_name)\n    else:\n        raise ValueError('Unknown dataset')\n    return dataset\n\ndef main():\n    \"\"\"\n    Main Function.\n\n    Training/Test/Plot\n    \"\"\"\n    args = parse_arguments()\n    print(vars(args))\n\n    device = torch.device('cuda')\n\n    # remove randomness\n    set_random_seed(args.seed)\n\n    # Set Dataset\n    dataset = setDataset(args.dataset, args.n_class, args.ind, False, args.seg_len)\n\n    checkpoints_dir = create_checkpoints_dir(\n        args.dataset,  args.num_blocks, args.hidden_size, args.code_length, args.estimator, args.hidden_size, args.K)\n    print(checkpoints_dir)\n\n    # Set Model\n    if (args.autoencoder is None):\n        print ('No Autoencoder')\n        c, h, w = dataset.shape\n        # build Density Estimator\n        if args.estimator == 'REALNVP':\n            model = TinvREALNVP(args.num_blocks, c*h*w, args.hidden_size).cuda()\n        elif args.estimator == 'GLOW':\n            model = Glow(\n                image_shape=(c, h, w),\n                hidden_channels=args.hidden_size,\n                K=args.K,\n                L=args.num_blocks,\n                actnorm_scale=1.0,\n                flow_permutation='invconv',\n                flow_coupling='affine',\n                LU_decomposed=True,\n                y_classes=10,\n                learn_top=True,\n                y_condition=False,\n                ).cuda()\n        else:\n            raise ValueError('Unknown Estimator')\n    else:\n        print(f'Autoencoder:{args.autoencoder}')\n        print(f'Density Estimator:{args.estimator}')\n        if args.autoencoder == \"LSA\":\n            if args.dataset in ['mnist', 'fmnist']:\n                model = LSA_MNIST(\n                    input_shape=dataset.shape,\n                    code_length=args.code_length,\n                    num_blocks=args.num_blocks,\n                    est_name=args.estimator,\n                    hidden_size=args.hidden_size).cuda()\n            elif args.dataset in ['cifar10', 'svhn', 'cifar100', 'celeba']:\n                model = LSA_CIFAR10(\n                    input_shape=dataset.shape,\n                    code_length=args.code_length,\n                    K=args.K,\n                    num_blocks=args.num_blocks,\n                    est_name=args.estimator,\n                    hidden_size=args.hidden_size,\n                    k=args.k,\n                    r=args.r).cuda()\n            else:\n                ValueError(\"Unknown Dataset\")\n        else:\n            raise ValueError('Unknown Autoencoder')\n\n\n    trainer = OODTrainer(\n        dataset=dataset,\n        model=model,\n        lam=args.lam,\n        checkpoints_dir=checkpoints_dir,\n        batch_size=args.batch_size,\n        lr=args.lr,\n        epochs=args.epochs,\n        code_length=args.code_length,\n        log_step=args.log_step,\n        device=device,\n        InD=args.ind,\n        num_epochs=args.num_epochs,\n        noise_flag=args.noise_flag,\n        sigma=args.sigma)\n\n    if args.trainflag:\n        trainer.train_ood_exp(args.ind)\n    elif args.testflag:\n        InD = args.ind\n        if len(InD) > 1:\n            trainer.test_ood_exp(args.ind)\n            dataset_InD = setDataset(InD, args.n_class, InD, False, args.seg_len)\n            trainer_InD = OODTrainer(\n                dataset=dataset_InD,\n                model=model,\n                lam=args.lam,\n                checkpoints_dir=checkpoints_dir,\n                batch_size=args.batch_size,\n                lr=args.lr,\n                epochs=args.epochs,\n                code_length=args.code_length,\n                log_step=args.log_step,\n                device=device,\n                InD=args.ind,\n                num_epochs=args.num_epochs,\n                noise_flag=args.noise_flag,\n                sigma=args.sigma)\n            trainer_InD.test_ood_exp(args.ind)\n            # plot histogram and ROC\n            if args.density_rule_flag:\n                trainer.plotDensityRule() # plot histogram and roc using density rule\n            elif args.kst_rule_flag:\n                if (args.autoencoder is None):\n                    trainer.plotKSTRuleRandPJ(args.num_project)  # plot histogram and roc using difference between distributions rule (ks-test)\n                else:\n                    trainer.plotKSTRule()\n            elif args.typical_flag:\n                epsilon = trainer_InD.getEpsilon()\n                trainer.plotTypicalityTest(epsilon)\n            elif args.klod_flag:\n                trainer.plotKLOD()\n        else:\n            trainer.test_ood_exp(args.ind)\n            dataset_InD = setDataset(args.dataset, args.n_class, InD, True, args.seg_len)\n            trainer_InD = OODTrainer(\n                dataset=dataset_InD,\n                model=model,\n                lam=args.lam,\n                checkpoints_dir=checkpoints_dir,\n                batch_size=args.batch_size,\n                lr=args.lr,\n                epochs=args.epochs,\n                code_length=args.code_length,\n                log_step=args.log_step,\n                device=device,\n                InD=args.ind,\n                num_epochs=args.num_epochs,\n                noise_flag=args.noise_flag,\n                sigma=args.sigma)\n            trainer_InD.test_ood_exp(args.ind)\n            if args.density_rule_flag:\n                trainer.plotDensityRule() # plot histogram and roc using density rule\n            elif args.kst_rule_flag:\n                if (args.autoencoder is None):\n                    pass\n                    # trainer.plotKSTRuleRandPJ(args.num_project)  # plot histogram and roc using difference between distributions rule (ks-test)\n                else:\n                    trainer.plotKSTRule()\n            elif args.klod_flag:\n                trainer.plotKLOD()\n            elif args.typical_flag:\n                epsilon = trainer_InD.getEpsilon()\n                trainer.plotTypicalityTest(epsilon)\n\n\nif __name__ == '__main__':\n    \"\"\"\n    entry point.\n    \"\"\"\n\n    start_t = time.time()\n    main()\n    print(\"Time cost: \", round(time.time() - start_t, 2), \"s.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:57:48.981782Z","iopub.execute_input":"2025-05-24T16:57:48.982607Z","iopub.status.idle":"2025-05-24T16:57:55.725577Z","shell.execute_reply.started":"2025-05-24T16:57:48.982572Z","shell.execute_reply":"2025-05-24T16:57:55.724763Z"}},"outputs":[{"name":"stdout","text":"{'autoencoder': None, 'estimator': 'REALNVP', 'dataset': 'mnist', 'ind': '1', 'trainflag': True, 'testflag': False, 'batch_size': 256, 'epochs': 200, 'lr': 1e-05, 'num_blocks': 1, 'code_length': 64, 'hidden_size': 2048, 'K': 3, 'n_class': 10, 'density_rule_flag': True, 'kst_rule_flag': True, 'klod_flag': True, 'typical_flag': False, 'num_project': 200, 'num_epochs': -1, 'lam': 1.0, 'seed': 1, 'log_step': 100, 'noise_flag': False, 'sigma': 1.0, 'seg_len': 10}\ncheckpoints/mnist/b1h2048c64/\nNo Autoencoder\nTesting on REALNVP\nTraining Set prepared, Num:6067\nCurrent epoch:  0 Total training epochs:  200\nTrain Epoch-1: 0\tLoss:-1774.350450\t\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2253726575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2253726575.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ood_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mInD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/OOD-flow/result_helpers/ood_trainer.py\u001b[0m in \u001b[0;36mtrain_ood_exp\u001b[0;34m(self, InD)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# train every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_every_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;31m# validate every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/OOD-flow/result_helpers/ood_trainer.py\u001b[0m in \u001b[0;36mtrain_every_epoch\u001b[0;34m(self, epoch, InD)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# save every log_step epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.train_llk_dir}_{epoch}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_llk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# save the log likelihood of the last training epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_llk_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_llk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \"\"\"\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnamedict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;31m# always force zip64, gh-10776\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mzipf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_zip64\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24,) + inhomogeneous part."],"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24,) + inhomogeneous part.","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"!ls -lthr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:32:41.830310Z","iopub.execute_input":"2025-05-24T16:32:41.830760Z","iopub.status.idle":"2025-05-24T16:32:41.978082Z","shell.execute_reply.started":"2025-05-24T16:32:41.830737Z","shell.execute_reply":"2025-05-24T16:32:41.977383Z"}},"outputs":[{"name":"stdout","text":"total 48K\n-rw-r--r-- 1 root root   50 May 24 15:39 __init__.py\n-rw-r--r-- 1 root root 6.8K May 24 15:39 utils.py\n-rw-r--r-- 1 root root  30K May 24 15:39 ood_trainer.py\ndrwxr-xr-x 2 root root 4.0K May 24 15:39 __pycache__\n","output_type":"stream"}],"execution_count":72}]}